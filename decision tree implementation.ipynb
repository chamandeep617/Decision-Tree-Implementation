{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "x_train,x_test,y_train,y_test = train_test_split(iris.data,iris.target,random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_tree_node:\n",
    "    def __init__(self,level,y,gain_ratio=None,point=None,feature=None):\n",
    "        self.level = level\n",
    "        self.y = y\n",
    "        self.gain_ratio = gain_ratio\n",
    "        self.feature = feature\n",
    "        self.point = point\n",
    "        self.right = None\n",
    "        self.left = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==>This function calculates the entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_calculator(y):\n",
    "    dic = Counter(y)\n",
    "    entropy = 0\n",
    "    keys = dic.keys()\n",
    "    total = len(y)\n",
    "    for i in keys:\n",
    "        key_value = dic[i]\n",
    "        pi = (key_value/total)\n",
    "        entropy+=(-1)*(pi*math.log(pi))/(math.log(2))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==>This function calculates the split number for each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_number(d,d1,d2):\n",
    "    num1 = d1/d\n",
    "    num2 = d2/d\n",
    "    return (-1)*((num1*math.log(num1)/math.log(2))+(num2*math.log(num2)/math.log(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==>This function returns the information gain of each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(entropy_old,entropy_new):\n",
    "    return entropy_old-entropy_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==>This function calculates the maximum gain ratio for each point in a particular feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_on_spliting_point(Xi,y,point,entropy_old):\n",
    "    temp = y.copy()\n",
    "    less_than_spliting_point = []\n",
    "    greater_or_equal_than_spliting_point = []\n",
    "    \n",
    "    for i in range(len(Xi)):\n",
    "        if(Xi[i]<point):\n",
    "            less_than_spliting_point.append(y[i])\n",
    "        else:\n",
    "            greater_or_equal_than_spliting_point.append(y[i])\n",
    "            \n",
    "    less_than_spliting_point = np.array(less_than_spliting_point)\n",
    "    greater_or_equal_than_spliting_point = np.array(greater_or_equal_than_spliting_point)\n",
    "    \n",
    "    entropy_less_than = entropy_calculator(less_than_spliting_point)\n",
    "    entropy_greater_than = entropy_calculator(greater_or_equal_than_spliting_point)\n",
    "    \n",
    "    d = len(y)\n",
    "    d1 = len(less_than_spliting_point)\n",
    "    d2 = len(greater_or_equal_than_spliting_point)\n",
    "    \n",
    "    entropy_new = (d1/d)*entropy_less_than+(d2/d)*entropy_greater_than\n",
    "    info_gain = information_gain(entropy_old,entropy_new)\n",
    "    split_num = split_number(d,d1,d2)\n",
    "    \n",
    "    gain_ratio = info_gain/split_num\n",
    "    return gain_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==>This function retruns the best splitting point in particular feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliting_point(Xi,y,entropy_old):\n",
    "    max_GR = 0\n",
    "    best_spliting_point = None\n",
    "    temp = Xi.copy()\n",
    "    temp.sort()\n",
    "    for i in range(Xi.shape[0]-1):\n",
    "        point = (temp[i]+temp[i+1])/2\n",
    "        if(point==temp[i]):\n",
    "            continue\n",
    "        Max = gain_on_spliting_point(Xi,y,point,entropy_old)\n",
    "        if(max_GR<Max):\n",
    "            max_GR = Max\n",
    "            best_spliting_point = point\n",
    "    return max_GR,best_spliting_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==>This function returns the best feature along with best splitting point for a particular node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_ratio(x,y):\n",
    "    entropy_old = entropy_calculator(y)\n",
    "    max_gain_ratio = 0\n",
    "    best_feature = None\n",
    "    best_spliting_point = None\n",
    "    for i in range(x.shape[1]):\n",
    "        gain_ratio,point = spliting_point(x[:,i],y,entropy_old)\n",
    "        if (gain_ratio>max_gain_ratio):\n",
    "            max_gain_ratio = gain_ratio\n",
    "            best_feature = i\n",
    "            best_spliting_point = point\n",
    "    return max_gain_ratio,best_spliting_point,best_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==>This function CREATES THE DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_tree(x,y,level = 0):\n",
    "    if(len(Counter(y))==1):\n",
    "        return Decision_tree_node(level,y,None,None,None)\n",
    "    best_gain_ratio,spliting_point,feature = gain_ratio(x,y)\n",
    "    node = Decision_tree_node(level,y,best_gain_ratio,spliting_point,feature)\n",
    "    \n",
    "    right_node = []\n",
    "    left_node = []\n",
    "    y_left = []\n",
    "    y_right = []\n",
    "    for i  in range(x.shape[0]):\n",
    "        if (x[i,feature]<spliting_point):\n",
    "            left_node.append(x[i])\n",
    "            y_left.append(y[i])\n",
    "        else:\n",
    "            right_node.append(x[i])\n",
    "            y_right.append(y[i])\n",
    "    right_node = np.array(right_node)\n",
    "    left_node = np.array(left_node)\n",
    "    y_left = np.array(y_left)\n",
    "    y_right = np.array(y_right)\n",
    "    \n",
    "    node.left = construct_tree(left_node,y_left,level+1)\n",
    "    node.right = construct_tree(right_node,y_right,level+1)\n",
    "    \n",
    "    return node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing Function Of Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(y):\n",
    "    dic = Counter(y)\n",
    "    key = dic.keys()\n",
    "    d = []\n",
    "    for i in range(len(dic)):\n",
    "        d.append(dic[i])\n",
    "    d =  np.array(d)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node,feature_names):\n",
    "    entropy = entropy_calculator(node.y)\n",
    "    \n",
    "    if(len(Counter(node.y))==1):\n",
    "        print(\"Level\",node.level)\n",
    "        print(\"Count of\",node.y[0],\"=\",len(node.y))\n",
    "        print(\"Current Entropy is =\",entropy)\n",
    "        print(\"Reached leaf Node \\n\")\n",
    "        return\n",
    "    \n",
    "    d = Counter(node.y)\n",
    "    key = set(node.y)\n",
    "    print(\"Level\",node.level)\n",
    "    for i in key:\n",
    "        print(\"count of\",i,\"=\",d[i])\n",
    "    print(\"Current Entropy is =\",entropy)\n",
    "    print(\"Splitting on feature\",feature_names[node.feature],\"with gain ratio\",node.gain_ratio,\"\\n\")\n",
    "    \n",
    "    print_tree(node.left,feature_names)\n",
    "    print_tree(node.right,feature_names)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Function Of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_one_input(x,node):\n",
    "    \n",
    "    while(node.point!=None):\n",
    "        point = node.point\n",
    "        feature = node.feature\n",
    "        if(x[feature]<point):\n",
    "            node = node.left\n",
    "        else:\n",
    "            node = node.right\n",
    "    return max(node.y,key = Counter(node.y).get)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,node):\n",
    "    y = []\n",
    "    for i in range(x.shape[0]):\n",
    "        y.append(predict_for_one_input(x[i],node))\n",
    "    y = np.array(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###                           ==========================DECISION TREE IMPLEMENTATION OVER==========================\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on dummy data (OR GATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0\n",
      "count of 0 = 1\n",
      "count of 1 = 3\n",
      "Current Entropy is = 0.8112781244591328\n",
      "Splitting on feature x1 with gain ratio 0.31127812445913283 \n",
      "\n",
      "Level 1\n",
      "count of 0 = 1\n",
      "count of 1 = 1\n",
      "Current Entropy is = 1.0\n",
      "Splitting on feature x2 with gain ratio 1.0 \n",
      "\n",
      "Level 2\n",
      "Count of 0 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node \n",
      "\n",
      "Level 2\n",
      "Count of 1 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node \n",
      "\n",
      "Level 1\n",
      "Count of 1 = 2\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,1],[0,1],[1,0],[0,0]])\n",
    "y = np.array([1,1,1,0])\n",
    "feature_name = np.array([\"x1\",\"x2\"])\n",
    "node = construct_tree(x,y)\n",
    "print_tree(node,feature_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying above implemented decision tree on iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0\n",
      "count of 0 = 37\n",
      "count of 1 = 34\n",
      "count of 2 = 41\n",
      "Current Entropy is = 1.5807197138422104\n",
      "Splitting on feature petal length (cm) with gain ratio 1.0 \n",
      "\n",
      "Level 1\n",
      "Count of 0 = 37\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node \n",
      "\n",
      "Level 1\n",
      "count of 1 = 34\n",
      "count of 2 = 41\n",
      "Current Entropy is = 0.993707106604508\n",
      "Splitting on feature petal width (cm) with gain ratio 0.6610420198933152 \n",
      "\n",
      "Level 2\n",
      "count of 1 = 33\n",
      "count of 2 = 4\n",
      "Current Entropy is = 0.4941829348497886\n",
      "Splitting on feature petal length (cm) with gain ratio 0.6941833044972409 \n",
      "\n",
      "Level 3\n",
      "Count of 1 = 32\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node \n",
      "\n",
      "Level 3\n",
      "count of 1 = 1\n",
      "count of 2 = 4\n",
      "Current Entropy is = 0.7219280948873623\n",
      "Splitting on feature sepal length (cm) with gain ratio 0.3315597072868287 \n",
      "\n",
      "Level 4\n",
      "count of 1 = 1\n",
      "count of 2 = 1\n",
      "Current Entropy is = 1.0\n",
      "Splitting on feature sepal width (cm) with gain ratio 1.0 \n",
      "\n",
      "Level 5\n",
      "Count of 2 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node \n",
      "\n",
      "Level 5\n",
      "Count of 1 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node \n",
      "\n",
      "Level 4\n",
      "Count of 2 = 3\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node \n",
      "\n",
      "Level 2\n",
      "count of 1 = 1\n",
      "count of 2 = 37\n",
      "Current Entropy is = 0.17556502585750278\n",
      "Splitting on feature petal length (cm) with gain ratio 0.18573556471891253 \n",
      "\n",
      "Level 3\n",
      "count of 1 = 1\n",
      "count of 2 = 3\n",
      "Current Entropy is = 0.8112781244591328\n",
      "Splitting on feature sepal width (cm) with gain ratio 1.0 \n",
      "\n",
      "Level 4\n",
      "Count of 2 = 3\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node \n",
      "\n",
      "Level 4\n",
      "Count of 1 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node \n",
      "\n",
      "Level 3\n",
      "Count of 2 = 34\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node \n",
      "\n"
     ]
    }
   ],
   "source": [
    "node = construct_tree(x_train,y_train)\n",
    "print_tree(node,iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the output of iris data using above implemented decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = predict(x_test,node)\n",
    "accuracy_score(predict,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  0,  0],\n",
       "       [ 0, 15,  1],\n",
       "       [ 0,  0,  9]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=predict, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      0.94      0.97        16\n",
      "           2       0.90      1.00      0.95         9\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        38\n",
      "   macro avg       0.97      0.98      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred=predict, y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Decision tree using sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = clf.predict(x_test)\n",
    "accuracy_score(predict,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  0,  0],\n",
       "       [ 0, 15,  1],\n",
       "       [ 0,  0,  9]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=predict, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      0.94      0.97        16\n",
      "           2       0.90      1.00      0.95         9\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        38\n",
      "   macro avg       0.97      0.98      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred=predict, y_true=y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
